{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.488642Z",
     "start_time": "2021-07-23T04:19:21.854534Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import yaml\n",
    "from train import train\n",
    "from utils import AttrDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.885144Z",
     "start_time": "2021-07-23T04:19:23.880564Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:24.119144Z",
     "start_time": "2021-07-23T04:19:24.112032Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_config(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)\n",
    "    opt = AttrDict(opt)\n",
    "    if opt.lang_char == 'None':\n",
    "        characters = ''\n",
    "        for data in opt['select_data'].split('-'):\n",
    "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
    "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "            all_char = ''.join(df['words'])\n",
    "            characters += ''.join(set(all_char))\n",
    "        characters = sorted(set(characters))\n",
    "        opt.character= ''.join(characters)\n",
    "    else:\n",
    "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
    "    # Ensure optimizer parameters are float\n",
    "    opt.lr = float(opt.lr)\n",
    "    opt.rho = float(opt.rho)\n",
    "    opt.eps = float(opt.eps)\n",
    "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:49:07.045060Z",
     "start_time": "2021-07-23T04:20:15.050992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: all_data\n",
      "opt.select_data: ['train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data\t dataset: train\n",
      "all_data/train\n",
      "sub-directory:\t/train\t num samples: 160\n",
      "num total samples of train: 160 x 1.0 (total_data_usage_ratio) = 160\n",
      "num samples of train per batch: 16 x 1.0 (batch_ratio) = 16\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 16 = 16\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data/val\t dataset: /\n",
      "all_data/val/\n",
      "sub-directory:\t/.\t num samples: 20\n",
      "--------------------------------------------------------------------------------\n",
      "No Transformation module specified\n",
      "model input parameters 64 600 20 1 256 256 326 34 None VGG BiLSTM CTC\n",
      "loading pretrained model from saved_models/japanese_g2.pth\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (FeatureExtraction): VGG_FeatureExtractor(\n",
      "      (ConvNet): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): ReLU(inplace=True)\n",
      "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): ReLU(inplace=True)\n",
      "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): ReLU(inplace=True)\n",
      "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "        (19): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Linear(in_features=256, out_features=326, bias=True)\n",
      "  )\n",
      ")\n",
      "Modules, Parameters\n",
      "module.FeatureExtraction.ConvNet.0.weight 288\n",
      "module.FeatureExtraction.ConvNet.0.bias 32\n",
      "module.FeatureExtraction.ConvNet.3.weight 18432\n",
      "module.FeatureExtraction.ConvNet.3.bias 64\n",
      "module.FeatureExtraction.ConvNet.6.weight 73728\n",
      "module.FeatureExtraction.ConvNet.6.bias 128\n",
      "module.FeatureExtraction.ConvNet.8.weight 147456\n",
      "module.FeatureExtraction.ConvNet.8.bias 128\n",
      "module.FeatureExtraction.ConvNet.11.weight 294912\n",
      "module.FeatureExtraction.ConvNet.12.weight 256\n",
      "module.FeatureExtraction.ConvNet.12.bias 256\n",
      "module.FeatureExtraction.ConvNet.14.weight 589824\n",
      "module.FeatureExtraction.ConvNet.15.weight 256\n",
      "module.FeatureExtraction.ConvNet.15.bias 256\n",
      "module.FeatureExtraction.ConvNet.18.weight 262144\n",
      "module.FeatureExtraction.ConvNet.18.bias 256\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.0.linear.weight 131072\n",
      "module.SequenceModeling.0.linear.bias 256\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.1.linear.weight 131072\n",
      "module.SequenceModeling.1.linear.bias 256\n",
      "module.Prediction.weight 83456\n",
      "module.Prediction.bias 326\n",
      "Total Trainable Params: 3840198\n",
      "Trainable params num :  2451782\n",
      "Optimizer:\n",
      "Adadelta (\n",
      "Parameter Group 0\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 1.0\n",
      "    maximize: False\n",
      "    rho: 0.95\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "number: 0123456789\n",
      "symbol: (¥,)-:+*!.;」]/・〈〉〒、~✕%@\"₋。\n",
      "lang_char: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZお造り三種盛点伝票軽油内税本体合計領 \n",
      "収書年月日時分様消費対象標準率上記正にいたしま株式会社木曽路徳川店名古屋市昭和区白金登録番号レ\n",
      "シート明綱飲食刺身手職個十六ぐろ天麩羅黄揚げ婦べ比膳等ご来誠あがとうざす支礦セルフ志賀公園愛知\n",
      "県北城町一クジッカド売取引通数量単価額承認払方法括利用可能ポイン獲得予定処理付横山ステム経営研\n",
      "究所車両申込代整備商品訳検者自賠責保険料重指続印紙証任意動現別小切券振鉄田丁目き焼初層か甲グラ\n",
      "タ楼海老の筍菜稚鮎馬籠茶蒸大ロホ酢味噌掛け蛤土瓶\n",
      "\n",
      "experiment_name: ja_receipt_cpu_demo\n",
      "train_data: all_data\n",
      "valid_data: all_data/val\n",
      "manualSeed: 1111\n",
      "workers: 1\n",
      "batch_size: 16\n",
      "num_iter: 10000\n",
      "valInterval: 500\n",
      "saved_model: saved_models/japanese_g2.pth\n",
      "FT: True\n",
      "optim: False\n",
      "lr: 1.0\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "select_data: ['train']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 1.0\n",
      "batch_max_length: 34\n",
      "imgH: 64\n",
      "imgW: 600\n",
      "rgb: False\n",
      "contrast_adjust: False\n",
      "sensitive: True\n",
      "PAD: True\n",
      "data_filtering_off: False\n",
      "Transformation: None\n",
      "FeatureExtraction: VGG\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: CTC\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 256\n",
      "hidden_size: 256\n",
      "decode: greedy\n",
      "new_prediction: True\n",
      "freeze_FeatureFxtraction: True\n",
      "freeze_SequenceModeling: False\n",
      "character: 0123456789(¥,)-:+*!.;」]/・〈〉〒、~✕%@\"₋。abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZお造り三種盛点伝票軽油内税本体合計領 \n",
      "収書年月日時分様消費対象標準率上記正にいたしま株式会社木曽路徳川店名古屋市昭和区白金登録番号レ\n",
      "シート明綱飲食刺身手職個十六ぐろ天麩羅黄揚げ婦べ比膳等ご来誠あがとうざす支礦セルフ志賀公園愛知\n",
      "県北城町一クジッカド売取引通数量単価額承認払方法括利用可能ポイン獲得予定処理付横山ステム経営研\n",
      "究所車両申込代整備商品訳検者自賠責保険料重指続印紙証任意動現別小切券振鉄田丁目き焼初層か甲グラ\n",
      "タ楼海老の筍菜稚鮎馬籠茶蒸大ロホ酢味噌掛け蛤土瓶\n",
      "\n",
      "num_class: 326\n",
      "---------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parvez427\\Dev\\receipt_project\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\parvez427\\Dev\\receipt_project\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  390.45523405075073\n",
      "149 tensor([121, 122, 101, 123, 310, 311, 308, 309, 189, 306, 305,  11,   2,   1,\n",
      "         32, 119, 120, 192, 292, 293, 240, 163, 323, 324, 313, 130, 322, 189,\n",
      "        306, 305,  96,  97,  76,  51,  35,   1,   1,   3,   8,   5,  34,  12,\n",
      "          6,  13,  10,   5,   1,  34, 315, 158, 246, 192, 292, 293, 292, 240,\n",
      "        163,  11, 314,  14,  34,  12,   3,   4,  13,   9,   9,   2,  34, 169,\n",
      "        170, 316, 301, 196, 235, 213, 305, 317, 318, 319, 320, 321, 173, 174,\n",
      "        175,  33,   2,   2,   1,   1], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 4,  2,  5,  6,  5,  4,  4, 10,  8,  9,  3,  9,  2, 11,  3,  5],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([ 11, 100, 117, 118, 101, 183, 310, 311,  17, 312, 313, 312, 313, 308,\n",
      "        309, 189, 306, 305], dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([6, 5, 2, 5], dtype=torch.int32)\n",
      "[500/10000] Train loss: 8.21745, Valid loss: 9.96286, Elapsed_time: 390.45563\n",
      "Current_accuracy : 10.000, Current_norm_ED  : 0.2657\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.2657\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "(内消費税等                    | 甲税の                       | 0.0193\tFalse\n",
      "馬籠+茶蒸                     | 標収号                       | 0.0728\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.8206422328948975\n",
      "training time:  389.58504724502563\n",
      "149 tensor([192, 292, 293, 240, 163, 173, 174, 175, 169, 170,  34,  12,   6,  13,\n",
      "         10,   5,   1,  34,  33,   2,   2,   1,   1,  11, 100, 117, 118, 101,\n",
      "        183,  96,  97,  76,  51,  35,   1,   1,   3,   8,   5, 322, 189, 306,\n",
      "        305, 121, 122, 101, 123,  11,   2,   1,  32, 119, 120, 310, 311,  17,\n",
      "        312, 313, 315, 158, 246, 192, 292, 293, 292, 240, 163, 310, 311,  34,\n",
      "         12,   3,   4,  13,   9,   9,   2,  34, 316, 301, 196, 235, 213, 305,\n",
      "        317, 318, 319, 320, 321,  11, 314,  14], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 5,  3,  2,  8,  5,  6, 10,  4,  4,  6,  5,  9,  2,  9, 11,  3],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([308, 309, 189, 306, 305, 323, 324, 313, 130, 308, 309, 189, 306, 305,\n",
      "        312, 313], dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([5, 4, 5, 2], dtype=torch.int32)\n",
      "[1000/10000] Train loss: 0.06192, Valid loss: 11.75234, Elapsed_time: 784.86171\n",
      "Current_accuracy : 10.000, Current_norm_ED  : 0.2744\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.2744\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "稚鮎と筍の                     | 名鉄払Nの                     | 0.0709\tFalse\n",
      "土瓶蒸し                      | 身0                        | 0.1525\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.450228452682495\n",
      "training time:  408.63471484184265\n",
      "149 tensor([323, 324, 313, 130, 310, 311,  17, 312, 313,  34,  12,   6,  13,  10,\n",
      "          5,   1,  34,  11, 100, 117, 118, 101, 183, 310, 311, 308, 309, 189,\n",
      "        306, 305, 192, 292, 293, 240, 163, 173, 174, 175,  11, 314,  14, 316,\n",
      "        301, 196, 235, 213, 305, 317, 318, 319, 320, 321,  34,  12,   3,   4,\n",
      "         13,   9,   9,   2,  34,  11,   2,   1,  32, 119, 120, 169, 170,  33,\n",
      "          2,   2,   1,   1, 121, 122, 101, 123,  96,  97,  76,  51,  35,   1,\n",
      "          1,   3,   8,   5], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 4,  5,  8,  6,  2,  5,  5,  3,  3, 11,  9,  6,  2,  5,  4, 10],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([315, 158, 246, 192, 292, 293, 292, 240, 163, 312, 313, 308, 309, 189,\n",
      "        306, 305, 322, 189, 306, 305], dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([9, 2, 5, 4], dtype=torch.int32)\n",
      "[1500/10000] Train loss: 0.01158, Valid loss: 11.18283, Elapsed_time: 1197.94704\n",
      "Current_accuracy : 5.000, Current_norm_ED  : 0.2661\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.2744\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ロースすき焼き定食                 | 曽                         | 0.0446\tFalse\n",
      "茶蒸                        | 量                         | 0.7323\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.612354278564453\n",
      "training time:  426.21308851242065\n",
      "149 tensor([308, 309, 189, 306, 305, 121, 122, 101, 123, 308, 309, 189, 306, 305,\n",
      "         33,   2,   2,   1,   1,  11, 314,  14, 316, 301, 196, 235, 213, 305,\n",
      "        317, 318, 319, 320, 321, 315, 158, 246, 192, 292, 293, 292, 240, 163,\n",
      "         11, 100, 117, 118, 101, 183, 323, 324, 313, 130, 169, 170, 173, 174,\n",
      "        175,  34,  12,   6,  13,  10,   5,   1,  34, 192, 292, 293, 240, 163,\n",
      "         96,  97,  76,  51,  35,   1,   1,   3,   8,   5, 310, 311, 310, 311,\n",
      "         17, 312, 313], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 5,  4,  5,  5,  3, 11,  9,  6,  4,  2,  3,  8,  5, 10,  2,  5],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([ 34,  12,   3,   4,  13,   9,   9,   2,  34, 322, 189, 306, 305, 312,\n",
      "        313,  11,   2,   1,  32, 119, 120], dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([9, 4, 2, 6], dtype=torch.int32)\n",
      "[2000/10000] Train loss: 0.00081, Valid loss: 11.00169, Elapsed_time: 1628.77289\n",
      "Current_accuracy : 5.000, Current_norm_ED  : 0.2761\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.2761\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "茶蒸                        | 量                         | 0.7219\tFalse\n",
      "(10%対象                    |                           | 0.1687\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.606451988220215\n",
      "training time:  423.2477226257324\n",
      "149 tensor([169, 170, 308, 309, 189, 306, 305, 121, 122, 101, 123, 316, 301, 196,\n",
      "        235, 213, 305, 317, 318, 319, 320, 321, 323, 324, 313, 130, 322, 189,\n",
      "        306, 305, 315, 158, 246, 192, 292, 293, 292, 240, 163, 192, 292, 293,\n",
      "        240, 163, 312, 313,  96,  97,  76,  51,  35,   1,   1,   3,   8,   5,\n",
      "        310, 311,  17, 312, 313, 173, 174, 175,  34,  12,   3,   4,  13,   9,\n",
      "          9,   2,  34,  33,   2,   2,   1,   1,  34,  12,   6,  13,  10,   5,\n",
      "          1,  34,  11, 100, 117, 118, 101, 183], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 2,  5,  4, 11,  4,  4,  9,  5,  2, 10,  5,  3,  9,  5,  8,  6],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([310, 311,  11, 314,  14,  11,   2,   1,  32, 119, 120, 308, 309, 189,\n",
      "        306, 305], dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([2, 3, 6, 5], dtype=torch.int32)\n",
      "[2500/10000] Train loss: 0.00084, Valid loss: 11.52504, Elapsed_time: 2056.62745\n",
      "Current_accuracy : 5.000, Current_norm_ED  : 0.2794\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.2794\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "馬籠                        | 白食                        | 0.3108\tFalse\n",
      "(大)                       |  株)                       | 0.1550\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.483291387557983\n",
      "training time:  426.15452122688293\n",
      "149 tensor([ 33,   2,   2,   1,   1, 121, 122, 101, 123, 310, 311, 173, 174, 175,\n",
      "         34,  12,   3,   4,  13,   9,   9,   2,  34, 312, 313, 315, 158, 246,\n",
      "        192, 292, 293, 292, 240, 163,  96,  97,  76,  51,  35,   1,   1,   3,\n",
      "          8,   5, 308, 309, 189, 306, 305,  11, 314,  14, 310, 311,  17, 312,\n",
      "        313, 323, 324, 313, 130, 322, 189, 306, 305, 316, 301, 196, 235, 213,\n",
      "        305, 317, 318, 319, 320, 321,  34,  12,   6,  13,  10,   5,   1,  34,\n",
      "        308, 309, 189, 306, 305], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 5,  4,  2,  3,  9,  2,  9, 10,  5,  3,  5,  4,  4, 11,  8,  5],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([192, 292, 293, 240, 163,  11, 100, 117, 118, 101, 183, 169, 170,  11,\n",
      "          2,   1,  32, 119, 120], dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([5, 6, 2, 6], dtype=torch.int32)\n",
      "[3000/10000] Train loss: 0.00212, Valid loss: 9.24409, Elapsed_time: 2487.26549\n",
      "Current_accuracy : 5.000, Current_norm_ED  : 0.2900\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.2900\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "(内消費税等                    | 、税等                       | 0.0146\tFalse\n",
      "十六                        | 十六                        | 0.9645\tTrue\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.659827470779419\n",
      "training time:  424.19062972068787\n",
      "149 tensor([323, 324, 313, 130, 310, 311, 192, 292, 293, 240, 163, 315, 158, 246,\n",
      "        192, 292, 293, 292, 240, 163, 322, 189, 306, 305, 308, 309, 189, 306,\n",
      "        305, 169, 170,  11, 100, 117, 118, 101, 183, 121, 122, 101, 123,  34,\n",
      "         12,   6,  13,  10,   5,   1,  34, 312, 313, 173, 174, 175,  11, 314,\n",
      "         14, 310, 311,  17, 312, 313,  96,  97,  76,  51,  35,   1,   1,   3,\n",
      "          8,   5, 308, 309, 189, 306, 305], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 4,  2,  5,  9,  4,  5,  2,  6,  4,  8,  2,  3,  3,  5, 10,  5],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([ 34,  12,   3,   4,  13,   9,   9,   2,  34,  11,   2,   1,  32, 119,\n",
      "        120,  33,   2,   2,   1,   1, 316, 301, 196, 235, 213, 305, 317, 318,\n",
      "        319, 320, 321], dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([ 9,  6,  5, 11], dtype=torch.int32)\n",
      "[3500/10000] Train loss: 0.00342, Valid loss: 11.24241, Elapsed_time: 2916.11618\n",
      "Current_accuracy : 5.000, Current_norm_ED  : 0.3231\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.3231\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "\"¥23,881\"                 | \"3,8812\"                  | 0.0612\tFalse\n",
      "(10%対象                    | 1ト                        | 0.2056\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.956143617630005\n",
      "training time:  427.44647884368896\n",
      "149 tensor([308, 309, 189, 306, 305, 310, 311,  34,  12,   3,   4,  13,   9,   9,\n",
      "          2,  34,  11,   2,   1,  32, 119, 120, 315, 158, 246, 192, 292, 293,\n",
      "        292, 240, 163, 173, 174, 175, 323, 324, 313, 130,  11, 100, 117, 118,\n",
      "        101, 183, 316, 301, 196, 235, 213, 305, 317, 318, 319, 320, 321, 312,\n",
      "        313,  11, 314,  14,  96,  97,  76,  51,  35,   1,   1,   3,   8,   5,\n",
      "        308, 309, 189, 306, 305, 192, 292, 293, 240, 163, 169, 170, 310, 311,\n",
      "         17, 312, 313], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 5,  2,  9,  6,  9,  3,  4,  6, 11,  2,  3, 10,  5,  5,  2,  5],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([121, 122, 101, 123, 322, 189, 306, 305,  33,   2,   2,   1,   1,  34,\n",
      "         12,   6,  13,  10,   5,   1,  34], dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([4, 4, 5, 8], dtype=torch.int32)\n",
      "[4000/10000] Train loss: 0.00018, Valid loss: 9.32351, Elapsed_time: 3348.51923\n",
      "Current_accuracy : 5.000, Current_norm_ED  : 0.3189\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.3231\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "標準税率                      | 準税率                       | 0.6728\tFalse\n",
      "蛤と筍の                      | 鉄N率                       | 0.1622\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.605592489242554\n",
      "training time:  430.8476724624634\n",
      "149 tensor([ 34,  12,   3,   4,  13,   9,   9,   2,  34, 322, 189, 306, 305, 173,\n",
      "        174, 175, 308, 309, 189, 306, 305, 312, 313, 192, 292, 293, 240, 163,\n",
      "         11, 100, 117, 118, 101, 183, 315, 158, 246, 192, 292, 293, 292, 240,\n",
      "        163,  34,  12,   6,  13,  10,   5,   1,  34, 323, 324, 313, 130, 169,\n",
      "        170,  11,   2,   1,  32, 119, 120,  11, 314,  14, 308, 309, 189, 306,\n",
      "        305, 121, 122, 101, 123,  33,   2,   2,   1,   1], dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([9, 4, 3, 5, 2, 5, 6, 9, 8, 4, 2, 6, 3, 5, 4, 5], dtype=torch.int32)\n",
      "149 tensor([316, 301, 196, 235, 213, 305, 317, 318, 319, 320, 321, 310, 311,  17,\n",
      "        312, 313, 310, 311,  96,  97,  76,  51,  35,   1,   1,   3,   8,   5],\n",
      "       dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([11,  5,  2, 10], dtype=torch.int32)\n",
      "[4500/10000] Train loss: 0.00011, Valid loss: 14.57010, Elapsed_time: 3783.97289\n",
      "Current_accuracy : 5.000, Current_norm_ED  : 0.3139\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.3231\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "馬籠                        | 白金                        | 0.4176\tFalse\n",
      "伝票No₋00274                | 482                       | 0.2212\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.578808784484863\n",
      "training time:  428.3147563934326\n",
      "149 tensor([310, 311, 173, 174, 175, 312, 313,  96,  97,  76,  51,  35,   1,   1,\n",
      "          3,   8,   5,  11,   2,   1,  32, 119, 120,  11, 314,  14, 192, 292,\n",
      "        293, 240, 163, 310, 311,  17, 312, 313,  11, 100, 117, 118, 101, 183,\n",
      "         33,   2,   2,   1,   1,  34,  12,   6,  13,  10,   5,   1,  34, 169,\n",
      "        170, 308, 309, 189, 306, 305, 308, 309, 189, 306, 305, 322, 189, 306,\n",
      "        305, 316, 301, 196, 235, 213, 305, 317, 318, 319, 320, 321],\n",
      "       dtype=torch.int32) tensor([149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149, 149,\n",
      "        149, 149], dtype=torch.int32) tensor([ 2,  3,  2, 10,  6,  3,  5,  5,  6,  5,  8,  2,  5,  5,  4, 11],\n",
      "       dtype=torch.int32)\n",
      "149 tensor([121, 122, 101, 123, 323, 324, 313, 130, 315, 158, 246, 192, 292, 293,\n",
      "        292, 240, 163,  34,  12,   3,   4,  13,   9,   9,   2,  34],\n",
      "       dtype=torch.int32) tensor([149, 149, 149, 149], dtype=torch.int32) tensor([4, 4, 9, 9], dtype=torch.int32)\n",
      "[5000/10000] Train loss: 0.00010, Valid loss: 10.43514, Elapsed_time: 4216.86704\n",
      "Current_accuracy : 5.000, Current_norm_ED  : 0.3139\n",
      "Best_accuracy    : 10.000, Best_norm_ED     : 0.3231\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "ロースすき焼き定食                 | き                         | 0.1234\tFalse\n",
      "\"¥23,881\"                 | \"3,81\"                    | 0.0602\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  4.629435062408447\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m opt = get_config(\u001b[33m\"\u001b[39m\u001b[33mconfig_files/ja_custom local.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\parvez427\\Dev\\receipt_project\\training\\EasyOCR\\trainer\\train.py:233\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(opt, show_number, amp)\u001b[39m\n\u001b[32m    231\u001b[39m     target = text[:, \u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# without [GO] Symbol\u001b[39;00m\n\u001b[32m    232\u001b[39m     cost = criterion(preds.view(-\u001b[32m1\u001b[39m, preds.shape[-\u001b[32m1\u001b[39m]), target.contiguous().view(-\u001b[32m1\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m \u001b[43mcost\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip) \n\u001b[32m    235\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\parvez427\\Dev\\receipt_project\\venv\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\parvez427\\Dev\\receipt_project\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\parvez427\\Dev\\receipt_project\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "opt = get_config(\"config_files/ja_custom local.yaml\")\n",
    "train(opt, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSystemExit\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m opt = get_config(\u001b[33m\"\u001b[39m\u001b[33mconfig_files/ja_custom local.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\parvez427\\Dev\\receipt_project\\training\\EasyOCR\\trainer\\train.py:296\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(opt, show_number, amp)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == opt.num_iter:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mend the training\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m i += \u001b[32m1\u001b[39m\n",
      "\u001b[31mSystemExit\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
